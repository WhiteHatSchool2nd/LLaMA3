# 24-06-02 UPDATE

## 데이터 로딩 최적화

먼저, 데이터 로딩 부분을 최적화했습니다. 주어진 코드에서 CSV 파일을 불러오고 데이터프레임으로 결합하는 과정에서 발생할 수 있는 비효율성을 해결했습니다.

### 원본 데이터 정리 및 전처리

- **데이터 프레임 로딩**: 여러 CSV 파일을 하나의 데이터프레임으로 결합하는 함수를 최적화했습니다.

- **결측값 처리**: 데이터프레임에서 결측값을 제거하고, 필요한 경우 NaN 값을 처리했습니다.

- **필요 없는 열 제거**: 모델 학습에 불필요한 열들을 제거했습니다.

- **정규화**: Min-Max 정규화를 적용하여 데이터 범위를 [0, 1]로 조정했습니다.

### 슬라이딩 윈도우 함수 정의

슬라이딩 윈도우 기법을 사용하여 시계열 데이터를 생성했습니다. 이 과정에서 다음과 같은 변경을 가했습니다:

- **창 크기 설정**: 적절한 윈도우 크기를 설정하여 모델이 시계열 데이터를 효과적으로 학습할 수 있도록 했습니다.

- **타겟 데이터 설정**: 각 윈도우에 대한 타겟 값을 정의하여 모델의 학습 목표를 명확히 했습니다.

### 데이터셋 분할

데이터를 훈련, 검증, 테스트 세트로 나누어 모델의 성능을 평가할 수 있도록 했습니다. 이를 통해 데이터의 분포를 균형 있게 유지하고, 과적합을 방지했습니다.

### LSTM 오토인코더 모델 정의

모델의 구조를 변경하여 더 깊은 LSTM 레이어와 드롭아웃을 추가했습니다.

- **모델 구조**: LSTM 레이어 수를 3으로 늘리고, 각 레이어에 드롭아웃을 추가하여 과적합을 방지했습니다.

- **히든 레이어 크기 조정**: 히든 레이어의 크기를 늘려 모델의 표현력을 강화했습니다.

### 하이퍼파라미터 설정

하이퍼파라미터를 조정하여 모델 성능을 최적화했습니다.

- **학습률**: 학습률을 적절히 설정하여 모델이 안정적으로 수렴할 수 있도록 했습니다.

- **에포크 수**: 에포크 수를 늘려 모델이 충분히 학습할 수 있게 했습니다.

- **배치 크기**: 배치 크기를 조정하여 GPU 메모리를 효율적으로 사용하도록 했습니다.

### 학습 루프와 조기 종료

- **학습 루프**: 모델 훈련 루프를 정의하고, 각 에포크마다 훈련 손실과 검증 손실을 출력했습니다.

- **조기 종료**: 검증 손실이 일정 에포크 동안 개선되지 않으면 학습을 중단하는 조기 종료를 도입하여 과적합을 방지했습니다.

- **학습률 스케줄러**: 검증 손실이 감소하지 않을 때 학습률을 줄이는 학습률 스케줄러를 도입했습니다.

### 평가와 시각화

- **모델 평가**: 테스트 데이터에서 모델의 성능을 평가하고, MSE, MAE, R^2 점수를 계산하여 모델의 정확도를 측정했습니다.

- **결과 시각화**: 실제 값과 예측 값을 비교하는 그래프를 생성하여 모델의 성능을 시각적으로 평가했습니다.

