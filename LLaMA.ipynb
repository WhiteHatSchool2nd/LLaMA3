{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install torch pandas numpy scikit-learn matplotlib\n",
    "!pip install torch torchvision torchaudio"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96vEiwiHCs21",
    "outputId": "27ee640c-17a5-4f41-eabe-e1a5d65e4993",
    "ExecuteTime": {
     "end_time": "2024-06-02T08:20:58.769321Z",
     "start_time": "2024-06-02T08:20:51.393367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\researcher\\anaconda3\\lib\\site-packages (2.3.0+cu121)\n",
      "Requirement already satisfied: pandas in c:\\users\\researcher\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\researcher\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\researcher\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\researcher\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: torch in c:\\users\\researcher\\anaconda3\\lib\\site-packages (2.3.0+cu121)\n",
      "Requirement already satisfied: torchvision in c:\\users\\researcher\\anaconda3\\lib\\site-packages (0.18.0+cu121)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\researcher\\anaconda3\\lib\\site-packages (2.3.0+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\researcher\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Set directories\n",
    "train_dir = Path(r\"C:\\Users\\Researcher\\Desktop\\LLaMA\\train\")\n",
    "test_dir = Path(r\"C:\\Users\\Researcher\\Desktop\\LLaMA\\test1\")\n",
    "\n",
    "# Verify files in directories\n",
    "train_files = list(train_dir.glob(\"*.csv\"))\n",
    "test_files = list(test_dir.glob(\"*.csv\"))\n",
    "\n",
    "print(\"Train files:\", train_files)\n",
    "print(\"Test files:\", test_files)\n",
    "\n",
    "# Load datasets\n",
    "def dataframe_from_csv(target):\n",
    "    return pd.read_csv(target).rename(columns=lambda x: x.strip())\n",
    "\n",
    "def dataframe_from_csvs(targets):\n",
    "    if not targets:\n",
    "        raise ValueError(\"No CSV files found in the directory.\")\n",
    "    return pd.concat([dataframe_from_csv(x) for x in targets])\n",
    "\n",
    "# Get dataset files\n",
    "TEST_DATASET = sorted([x for x in test_dir.glob(\"*.csv\")])\n",
    "TRAIN_DATASET = sorted([x for x in train_dir.glob(\"*.csv\")])\n",
    "\n",
    "# Load dataframes\n",
    "try:\n",
    "    TEST_DF_RAW = dataframe_from_csvs(TEST_DATASET)\n",
    "    TRAIN_DF_RAW = dataframe_from_csvs(TRAIN_DATASET)\n",
    "except ValueError as e:\n",
    "    print(e)\n",
    "    TRAIN_DF_RAW = pd.DataFrame()\n",
    "    TEST_DF_RAW = pd.DataFrame()\n",
    "\n",
    "# Check if dataframes are not empty\n",
    "if not TRAIN_DF_RAW.empty and not TEST_DF_RAW.empty:\n",
    "    ATTACK_DF = TEST_DF_RAW['attack']\n",
    "    DROP_FIELD = [\"time\", \"attack_P1\", \"attack_P2\", \"attack_P3\", \"attack\"]\n",
    "    VALID_COLUMNS_IN_TRAIN_DATASET = TRAIN_DF_RAW.columns.drop(DROP_FIELD)\n",
    "\n",
    "    # Min-Max normalization\n",
    "    TAG_MIN = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].min()\n",
    "    TAG_MAX = TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET].max()\n",
    "\n",
    "    def normalize(df, TAG_MIN, TAG_MAX):\n",
    "        ndf = df.copy()\n",
    "        for c in df.columns:\n",
    "            if TAG_MIN[c] == TAG_MAX[c]:\n",
    "                ndf[c] = df[c] - TAG_MIN[c]\n",
    "            else:\n",
    "                ndf[c] = (df[c] - TAG_MIN[c]) / (TAG_MAX[c] - TAG_MIN[c])\n",
    "        return ndf\n",
    "\n",
    "    # Apply normalization and exponential weighted moving average\n",
    "    TRAIN_DF = normalize(TRAIN_DF_RAW[VALID_COLUMNS_IN_TRAIN_DATASET], TAG_MIN, TAG_MAX).ewm(alpha=0.9).mean()\n",
    "\n",
    "    def boundary_check(df):\n",
    "        x = np.array(df, dtype=np.float32)\n",
    "        return np.any(x > 1.0), np.any(x < 0), np.any(np.isnan(x))\n",
    "\n",
    "    print(boundary_check(TRAIN_DF))\n",
    "    print(TRAIN_DF.shape)\n",
    "    train = np.array(TRAIN_DF)\n",
    "    x_train = train.reshape(train.shape[0], 1, train.shape[1])\n",
    "    print(len(TEST_DF_RAW))\n",
    "    TEST_DF_RAW = TEST_DF_RAW.dropna()\n",
    "    print(len(TEST_DF_RAW))\n",
    "else:\n",
    "    print(\"No training or testing data found. Please upload the files and try again.\")\n",
    "\n",
    "# Define sliding window function\n",
    "window_size = 60\n",
    "label_size = 100000\n",
    "\n",
    "def sliding_window_unsupervised(df, window_size, feature_columns, answer_column):\n",
    "    data = df[feature_columns].values\n",
    "    answers = answer_column.values\n",
    "\n",
    "    num_samples = len(df) - window_size\n",
    "    features = np.empty((num_samples, window_size, len(feature_columns)), dtype=np.float32)\n",
    "    targets = np.empty((num_samples, window_size, len(feature_columns)), dtype=np.float32)\n",
    "    answer_targets = np.empty(num_samples, dtype=int)\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        features[i] = data[i:i+window_size]\n",
    "        targets[i] = data[i+window_size]\n",
    "        answer_targets[i] = 1 if np.any(answers[i:i+window_size] == 1) else 0\n",
    "\n",
    "    return features, targets, answer_targets\n",
    "\n",
    "feature_columns = ['P1_B2004', 'P1_B2016', 'P1_B3004', 'P1_B3005', 'P1_B4002', 'P1_B4005', 'P1_B400B',\n",
    "                   'P1_B4022', 'P1_FCV01D', 'P1_FCV01Z', 'P1_FCV02D', 'P1_FCV02Z', 'P1_FCV03D',\n",
    "                   'P1_FCV03Z', 'P1_FT01', 'P1_FT01Z', 'P1_FT02', 'P1_FT02Z', 'P1_FT03', 'P1_FT03Z',\n",
    "                   'P1_LCV01D', 'P1_LIT01', 'P1_PCV01D', 'P1_PCV01Z', 'P1_PCV02D', 'P1_PCV02Z',\n",
    "                   'P1_PIT01', 'P1_PIT02', 'P1_TIT01', 'P1_TIT02']\n",
    "\n",
    "features, targets, answers = sliding_window_unsupervised(TRAIN_DF[:label_size], 60, feature_columns, ATTACK_DF[:label_size])\n",
    "print(features.shape)\n",
    "print(targets.shape)\n",
    "print(answers.shape)\n",
    "\n",
    "# Split into train, validation, and test sets\n",
    "features_train, features_valid, targets_train, targets_valid, labels_train, labels_valid = train_test_split(features, targets, answers, test_size=0.2, random_state=42)\n",
    "features_train, features_test, targets_train, targets_test, labels_train, labels_test = train_test_split(features_train, targets_train, labels_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Define a deeper LSTM autoencoder with dropout\n",
    "class LLaMA3Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, seq_len):\n",
    "        super(LLaMA3Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Linear(input_dim, hidden_dim)\n",
    "        self.decoder = nn.Linear(hidden_dim, input_dim)\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, num_layers=3, batch_first=True, dropout=0.2)  # Increased LSTM layers with dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        x = self.encoder(x)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.decoder(x[:, -1, :])  # Only decode the last time step\n",
    "        return x\n",
    "\n",
    "# Set hyperparameters\n",
    "input_dim = len(feature_columns)\n",
    "hidden_dim = 256  # Increased hidden dimension\n",
    "seq_len = window_size\n",
    "lr = 0.0005  # Adjusted learning rate\n",
    "epochs = 100  # Increased epochs for better training\n",
    "batch_size = 128  # Increased batch size\n",
    "\n",
    "# Initialize the model\n",
    "model = LLaMA3Autoencoder(input_dim, hidden_dim, seq_len).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)  # Learning rate scheduler\n",
    "\n",
    "# Convert data to tensors and create DataLoader\n",
    "train_dataset = TensorDataset(torch.tensor(features_train, dtype=torch.float32), torch.tensor(targets_train[:, -1, :], dtype=torch.float32))\n",
    "valid_dataset = TensorDataset(torch.tensor(features_valid, dtype=torch.float32), torch.tensor(targets_valid[:, -1, :], dtype=torch.float32))\n",
    "test_dataset = TensorDataset(torch.tensor(features_test, dtype=torch.float32), torch.tensor(targets_test[:, -1, :], dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Training loop with validation and early stopping\n",
    "best_valid_loss = float('inf')\n",
    "early_stopping_patience = 10\n",
    "no_improvement_count = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for batch_features, batch_targets in train_loader:\n",
    "        batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    \n",
    "    model.eval()\n",
    "    total_valid_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_targets in valid_loader:\n",
    "            batch_features, batch_targets = batch_features.to(device), batch_targets.to(device)\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            total_valid_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_valid_loss = total_valid_loss / len(valid_loader)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {avg_train_loss}, Valid Loss: {avg_valid_loss}')\n",
    "\n",
    "    # Save the model if validation loss decreases\n",
    "    if avg_valid_loss < best_valid_loss:\n",
    "        best_valid_loss = avg_valid_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        no_improvement_count = 0\n",
    "    else:\n",
    "        no_improvement_count += 1\n",
    "\n",
    "    scheduler.step(avg_valid_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if no_improvement_count >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "# Load the best model\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Evaluation on test data\n",
    "model.eval()\n",
    "predicted = []\n",
    "with torch.no_grad():\n",
    "    for batch_features, _ in test_loader:\n",
    "        batch_features = batch_features.to(device)\n",
    "        outputs = model(batch_features)\n",
    "        predicted.append(outputs.cpu().numpy())\n",
    "predicted = np.concatenate(predicted, axis=0)\n",
    "\n",
    "# Plot actual vs predicted values\n",
    "num_plots = 5  # Number of samples to plot\n",
    "\n",
    "plt.figure(figsize=(15, num_plots * 5))\n",
    "for i in range(num_plots):\n",
    "    plt.subplot(num_plots, 1, i+1)\n",
    "    plt.plot(features_test[i, -1, :].flatten(), label='Actual')\n",
    "    plt.plot(predicted[i].flatten(), label='Predicted')\n",
    "    plt.legend()\n",
    "    plt.title(f'Sample {i+1}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional evaluation metrics\n",
    "mse = np.mean((predicted - features_test[:, -1, :]) ** 2)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "# Calculate MAE and R^2 Score\n",
    "mae = mean_absolute_error(features_test[:, -1, :], predicted)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\n",
    "r2 = r2_score(features_test[:, -1, :], predicted)\n",
    "print(f'R^2 Score: {r2}')"
   ],
   "metadata": {
    "id": "5ijso9Za80E5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b93961c8-e223-4ef1-9d43-171b0304c856",
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-06-02T09:46:04.303094Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train files: [WindowsPath('C:/Users/Researcher/Desktop/LLaMA/train/train1.csv'), WindowsPath('C:/Users/Researcher/Desktop/LLaMA/train/train2.csv')]\n",
      "Test files: [WindowsPath('C:/Users/Researcher/Desktop/LLaMA/test1/test1.csv'), WindowsPath('C:/Users/Researcher/Desktop/LLaMA/test1/test2.csv')]\n",
      "(False, False, False)\n",
      "(550800, 59)\n",
      "444600\n",
      "444600\n",
      "(99940, 60, 30)\n",
      "(99940, 60, 30)\n",
      "(99940,)\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-02T08:38:40.374429Z",
     "start_time": "2024-06-02T08:38:40.363991Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ]
}
